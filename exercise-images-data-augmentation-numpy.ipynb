{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# ML-Fundamentals - Images Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Requirements](#Requirements) \n",
    "  * [Knowledge](#Knowledge) \n",
    "  * [Modules](#Python-Modules)\n",
    "* [Data](#Data)\n",
    "* [Exercises](#Exercises)\n",
    "  * [Exercise - Mirroring](#Exercise---Mirroring)\n",
    "  * [Exercise - Cropping](#Exercise---Cropping)\n",
    "  * [Exercise - Rotation](#Exercise---Rotation)\n",
    "  * [Exercise - Noise](#Exercise---Noise)\n",
    "  * [Exercise - Combine Everything](#Exercise---Combine-Everything)\n",
    "* [Summary and Outlook](#Summary-and-Outlook)\n",
    "* [Literature](#Literature) \n",
    "* [Licenses](#Licenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "When trying to solve image recognition tasks like *image classification* or *image segmentation* having enough training data is one of the most important things. But even if you might think you have enough, more is always better.\n",
    "\n",
    "In this notebook you will practice common techniques to get the most out of your data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "### Knowledge\n",
    "\n",
    "You should have a basic knowledge of:\n",
    "- numpy\n",
    "\n",
    "Suitable sources for acquiring this knowledge are:\n",
    "- [numpy quickstart](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Python Modules\n",
    "\n",
    "By [deep.TEACHING](https://www.deep-teaching.org/) convention, all python modules needed to run the notebook are loaded centrally at the beginning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Here we define a batch of images we will use to test our methods. They contain the least features necessary to do the planned operations and do not distract from the effect by containing too many details. Just execute the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 2\n",
    "width = 8\n",
    "height = 8\n",
    "colors = 3\n",
    "images = np.full((n_images,height,width,colors), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs):\n",
    "    for i in range(len(imgs)):\n",
    "        ax = plt.subplot(1,len(imgs),i+1)\n",
    "        ax.imshow(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tmp = width//2\n",
    "h_tmp = height//2\n",
    "\n",
    "images[0,:h_tmp,:w_tmp,0] = 50\n",
    "images[0,:h_tmp,:w_tmp,1] = 50\n",
    "images[0,h_tmp:,:w_tmp,1] = 0\n",
    "images[0,h_tmp:,:w_tmp,2] = 0\n",
    "    \n",
    "images[1,:h_tmp,:w_tmp,0] = 50\n",
    "images[1,:h_tmp,:w_tmp,2] = 50\n",
    "images[1,:h_tmp,w_tmp:,1] = 150\n",
    "images[1,:h_tmp,w_tmp:,2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[images > 255] = 255\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Let us practice some common techniques here. Always keep in mind, that not all techniques can be applied (or make sense) to all kinds of images as explained briefly at the individual exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Mirroring\n",
    "\n",
    "Mirroring, or also flipping, has the advantage, that the aspect ratio of the image does not change. An image of 100x50 pixel e.g. will stay 100x50. Real world images like photographs of houses, animals, cars, etc. can most likely always be mirrored at the vertical axes. Mirroring up and down is often not a good idea since it does not make much sense to have a photo where the sky is at the bottom and the car is driving on the top.\n",
    "Cases where it might make sense are photos which were take from the air only showing the ground, such as images of microscopy or astronomy.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement the functions to mirror the whole batch of images and return the result.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Always use *numpy* methods. You should never need to implement a loop in this exercise.\n",
    "\n",
    "Your plots should look like the following:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_mirror_up_down.png)\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_mirror_left_right.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_batch_up_down(imgs):\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def mirror_batch_left_right(imgs):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(mirror_batch_up_down(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images(mirror_batch_left_right(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Cropping\n",
    "\n",
    "Cropping is an excellent technique to multiply your data set by a big order. Imagine you have images of the size 256x256. By cropping a random 224x224 piece, you get $(256-224)^2 = 32^2 = 1024$ different crops from it! But take care you do not crop too much, so meaningful parts do not vanish. For example, an image labeled with the class cat and the cat sits in the 32x32 bottom left corner only.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Implement the function to **randomly** crop a $a x a$ piece from your batch, with , $0 < a < 8$\n",
    "\n",
    "The region that is cropped is randomly picked. Your plots may look like the following:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_cropping.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(imgs, a):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(crop(images, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Rotation\n",
    "\n",
    "There are many possibilities we can rotate our images. The easiest way, which does not create any artifacts, are rotations by 90, 180 and 270 degrees. Note that the aspect ratio changes when rotating by 90 or 270 degrees. Again these heavy rotations do often only make sense with data of microscopy or astronomy. Rotation by smaller angles (like 5 degrees) on the other hand can be used with real world photos. However, there you have to handle artifacts, which will occur. Also the image will not fit in the same array anymore. A common practice there is to rotate by like 2, 3 degrees and then just crop the center of the image, so it still fits into an array.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Implement the functions to rotate the whole batch of images by a multiple (param `k`) of 90 degrees.\n",
    "2. Implement the function to rotate the batch by 45 degrees and crop as little as needed to fit the image into an array.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "For 2. you can use methods of the `scipy.ndimage` package.\n",
    "\n",
    "Your plots should look like the following:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_rotate90.png)\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_rotate45.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_batch_by_k_times_90_degree(imgs, k):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_images(rotate_batch_by_k_times_90_degree(images, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_batch(imgs, degree=45):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rotate_batch(images, 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Noise\n",
    "\n",
    "Adding noise is also a good technique to help your model generalize better.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Implement the function to apply a small random noise to your images.\n",
    "\n",
    "Your plots may look like the following:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_noise.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(imgs):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_images(add_noise(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Combine Everything\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Finally implement the method `get_augmented_data`, which combines all methods randomly with a certain chance (except rotatation of 45 degree).\n",
    "\n",
    "Your plots should look like the following:\n",
    "\n",
    "![internet connection needed](https://gitlab.com/deep.TEACHING/educational-materials/raw/master/media/klaus/data_augm_all.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_data(imgs):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(get_augmented_data(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Summary and Outlook\n",
    "\n",
    "In this exercise you implemented techniques to modify a batch of images\n",
    "* mirroring\n",
    "* cropping\n",
    "* rotation\n",
    "* adding noise\n",
    "\n",
    "You learned in which scenarios each of the methods are useful and how you combine them to get the most out of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Licenses\n",
    "\n",
    "### Notebook License (CC-BY-SA 4.0)\n",
    "\n",
    "*The following license applies to the complete notebook, including code cells. It does however not apply to any referenced external media (e.g., images).*\n",
    "\n",
    "Exercise: Images Data Augmentation <br/>\n",
    "by Klaus Strohmenger<br/>\n",
    "is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).<br/>\n",
    "Based on a work at https://gitlab.com/deep.TEACHING.\n",
    "\n",
    "\n",
    "### Code License (MIT)\n",
    "\n",
    "*The following license only applies to code cells of the notebook.*\n",
    "\n",
    "Copyright 2018 Klaus Strohmenger\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep_teaching_kernel",
   "language": "python",
   "name": "deep_teaching_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
